## Kernel-PCA

#### Principle: non linear transformation of $\bx$ prior to linear PCA

  1. Project the data into a higher space where it is linearly separable
  2. Apply PCA to the transformed data 

![Transformation $\Psi : \bx \to \Psi(\bx)$ (illustration in presence of existing labels)](figs_common/kernel_trick.png){height=2.5cm}

####  Model

Assume a non linear transformation $\Psi(\mathbf{x}_i) \text{ where } \Psi : \mathbb{R}^p \to \mathbb{R}^n$,  then perform PCA, with $\bV_q$ a \emphase{$n\times q$} orthonormal matrix

$$
\Phi(\bx) = \bV_q^\top \Psi(\bx-\bmu) = \bz
$$

## Choice of the transformation

All relationships are described in terms of scalar products between $(\bx_i,\bx_{i'})$:

$$
K = k(\bx_1,\bx_2) = (\Psi(\bx)_i,\Psi(\bx_{i'})) = \Psi(\bx_i)^\top \Psi(\bx_{i'}),
$$

where the kernel $K$ is a symmetric positive definite function.

#### Some common kernels

$$\begin{array}{lcr} 
  \text{\emphase{Polynormial}:} &  k(\bx_i,\bx_{i'}) & = (\bx_{i}^\top \bx_{i'} + c)^d \\[2ex]
  \text{\emphase{Gaussian}:} & k(\bx_i,\bx_{i'}) & = \exp{\frac {-\left\|\bx_i - \bx_{i'} \right\|^2}{2\sigma^2}} \\[2ex]
  \text{\emphase{Laplacian kernel}:} & k(\bx_i,\bx_{i'}) & = \exp{\frac {-\left\|\bx_i - \bx_{i'} \right\|}{\sigma}} \\
\end{array}$$

\bigskip

\rsa Kernel PCA suffers from the choice of the Kernel
